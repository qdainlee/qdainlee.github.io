---
layout: single
title: "Graph Convolutional Network"
categories:
  - Blog
mathjax: true
---

## Introduction
반말 쓸 거야. 기분 나쁘면 메일 보내.

지금부터의 내용은  

***

Kipf, 2016, SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS

***

에 근거해.

Graph, node와 edge로 구성된 graph에서 **Node classification**을 하려고 해.
어떤 node는 class를 알고, 어떤 node는 class를 모를 때, 모르는 node의 class를 맞춰보겠다는 소리야.

잠시 생각해보면, 쉬운 일이야. 소셜 네트워크를 생각해봐.
내 친구들은 다 대학원생인데, 나도 대학원생 아니겠어?

이를 수식으로 나타내면,   
  $$\mathcal{L} = \mathcal{L}_0 + \lambda\mathcal{L}_{reg},\ with\ \mathcal{L}_{reg} = \sum\limits_{i,j}A_{ij}||f(X_i)-f(X_j)||^2 \ =\ f(X)^\intercal \Delta f(X)$$

그냥 흘려 읽어. 수식을 찬찬히 읽어보면, node와 node의 feature($$X_i$$ , $$X_j$$)가 비슷하고, 연결되어 있으면($$A_{ij} \not= 0$$), 비슷한 class로 추정하게끔 유도한 loss function임을 알 수 있어.

나는 대학원생이고, 너는 누군지 모르겠지만 GCN에 관심을 가지고 있고, 우린 이 블로그로 연결되어 있으니, 너도 대학원생일 거라는 소리야.

꽤 괜찮아 보여. 근데, 문제가 되는 가정이 있어. Node가 연결되어 있으면, 비슷할 거라는 거야. 내 친구는 연예인만 수백명을 팔로우 하는데, 연예인은 아니거든. 또 문제는, $$\mathcal{L}_0$$ 와 $$\mathcal{L}_{reg}$$ 가 구분되어 있다는 거야. Regularization term에서 $$\lambda$$ 를 얼마나 크게 해야할 지 결정해야 하는데, 벌써 머리가 아파.  

우리, Regularization term을 따로 두지 말고, 문제를 해결해보자! 이게 Graph Convolutional Network(GCN) 탄생의 시발점이야.


## Spectral Graph Convolution
재미없겠지만, Spectral convolution에 대해서 먼저 알아보자.
넘어가려면 넘어가.
Spectral convolution, 너무 어려운 말이야.
우리 쉽게 가자.
Spectral decomposition은 음성/이미지/그래프를 간단한 성분들의 조합(basis set)으로 분해하겠다는 거야.
Fourier transform 들어봤지?
비슷한 거야.

음성/이미지에서는 spectral이 Fourier transfrom이라면, 그래프에서의 spectral은 그래프 Laplacian의 eigen decomposition이야.
Laplacian에 대한 설명은 [튜토리얼 논문](https://arxiv.org/abs/0711.0189)을 참고해 봐.
개념적으로만 설명해 보자면, 그래프의 구조에 대한 정보를 담고 있는 그래프 Laplacian에서 간단한 성분들의 정보를 뽑아.
그리고 그 성분들이 node가 업데이트되는 방법을 담고 있어.

Spectral convolution의 정의는 다음과 같아.
$$g_\theta\ \star x\ = \ Ug_\theta U^\intercal x $$
$$L = I_N - D^{-\frac{1}{2}}AD^{\frac{1}{2}} = U\Lambda U^\intercal$$

근데, 이 방법은 

졸리니 나중에 작성하겠음.
